import {
  CodeSurfer,
  CodeSurferColumns,
  Step,
} from 'code-surfer';

import {
  Image,
  Invert,
  Notes,
  Split,
  SplitRight,
  Appear,
  Head,
} from 'mdx-deck';

import { github, dracula } from '@code-surfer/themes';
import customTheme from '../custom-theme';
export const theme = customTheme(dracula);

import ImageLayout from '../image-split-layout';
import * as imgs from '../images';
import VideoUserMedia from '../video-user-media';
import AudioUserMedia from '../audio-user-media';

<Head>
  <title>Shriek!</title>
  {Object.values(imgs).map(function (img) {
    <link rel="preload" as="image" href={img} />;
  })}
</Head>

<Image
  src={imgs.bg}
  style={{
    display: 'flex',
    alignItems: 'center',
    justifyContent: 'center',
    paddingRight: '1rem',
    color: 'black',
    backgroundColor: 'black',
  }}
>


# Shriek

</Image>


<Notes>


Med programmering i verktøy beltet kan du gjøre det utroligste. På sitt beste kan det revolusjonere verden, på sitt verste ødelegge for generasjoner. ...eller du kan lage ditt eget spill som styres av deg og din venns evne til å rope høyt og ukontrollert. I dette kurset ser vi på hvordan vi kan bruke innebygde API-er i nettleseren, litt matematikk og en dose kreativitet til å lage vår egen utgave av Supermarked Shriek.

</Notes>


---

## User Media

- MediaDevices-API brukes for tilgang til diverse media
- `getUserMedia` for tilgang til kamera eller mikrofon
- Krever "Secure Context"
- Styrer permissions

<Notes>
 I nettleser-API som omhandler "Media Devices" kan du be om tilgang til kamera eller mikrofon via `getUserMedia`.


Dette må lastes i en "secure context", som betyr at det må vanligvis skje via HTTPS. Dette er grunnet personvern, og nettleser vil prøve å sikre at ingen blir spionert på via usikre tilkoblinger. Unntaket fra denne regelen er hvis nettsiden er hostet lokalt, slik som via localhost. Da blir det sett på som en "secure context"

Denne tilgangen til en gitt ressurs, slik som kamera eller mikrofon, håndteres via permissions i nettleser. Som betyr at brukeren kan trekke tilbake tilgang når hen vil, og derfor må løsninger som bruker "user media" være ganske godt skrudd sammen for å håndtere at tilgang skrus av.

Men heldigvis, siden nettleseren tilbyr grensesnittet og funksjonalitet for å justere tilganger, samt hvilke kilder du skal ha tilgang til, så er det ikke mye kode som skal til i dette scenarioet.

  </Notes>


---

<CodeSurfer>


```ts subtitle="Det å lytte på webkamera kan gjøres på noen få linjer"
async function getMediaStream() {
  const mediaStream = await navigator.mediaDevices.getUserMedia(
    {
      video: true,
    },
  );

  const video = document.querySelector('video');
  video.srcObject = mediaStream;
}

// Du må ha et video-element i DOM:
// <video autoPlay />
```

```diff 2[29:63] subtitle="Kalle getUserMedia"

```

```diff 4 subtitle="Send inn at du vil ha video"

```

```diff 8,9 subtitle="Sette stream til video-elementet som finnes i DOM"

```

</CodeSurfer>


---

Voila!

<VideoUserMedia />

<Notes>
  Og koden du så tidligere var bokstavelig talt det som
  skulle til for å vise video her
</Notes>

---

## Web Audio API

- AudioContext
- Streams, buffers

<Notes>
  For å gjøre noe med lyd fra mikronen, kan vi ta i bruk Web
  Audio API-et


Her kommer vi også innom streams og buffers

</Notes>


---

<CodeSurfer>


```ts subtitle="I stedet for å be om video,"
const stream = await navigator.mediaDevices.getUserMedia({
  video: true,
});
```

```ts subtitle="Så kan du be om audio"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
```

```ts subtitle="AudioContext er fundamentet i Web Audio"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
```

```ts subtitle="Vi kan bruke mikrofonen som lydkilde"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);
```

```ts subtitle="Prosessering av lyd går igjennom AudioNodes"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);
const volumeNode = audioContext.createGain();
```

```ts subtitle="Så kan du gjøre operasjoner på lyden"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);
const volumeNode = audioContext.createGain();
volumeNode.gain.setValueAtTime(2, audioContext.currentTime);
```

```ts subtitle="Og du kan analysere lyden"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);
const volumeNode = audioContext.createGain();
volumeNode.gain.setValueAtTime(2, audioContext.currentTime);
const analyser = audioContext.createAnalyser();
```

```ts subtitle="Og nodene linkes sammen i AudioContext og rutes ut"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);
const volumeNode = audioContext.createGain();
volumeNode.gain.setValueAtTime(2, audioContext.currentTime);
const analyser = audioContext.createAnalyser();
source
  .connect(volumeNode)
  .connect(analyser)
  .connect(audioContext.destination);
```

</CodeSurfer>


<Notes>
  AudioContext er boksen som inneholder alt av det som skjer
  av audio-håndtering i Web Audio. Den gjør operasjoner på
  lyd via det som kalles audio nodes, som kan linkes sammen
  på en modulær måte for å rute lyden og gjøre operasjoner
  på den.
</Notes>

---

<AudioUserMedia />

---

<Image src={imgs.audioContext} />

---

## AudioWorklet

- En worklet, nesten som en Web Worker
- Gir tilgang til lavere nivå i render pipeline
- Brukes når det er behov for mye prosessering
- Krever "Secure Context"

---

<CodeSurfer>


```ts subtitle="Hvis vi har tilgang til mikrofon"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);

source.connect(audioContext.destination);
```

```ts subtitle="Så kan vi laste inn en audio-worklet"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);

await audioContext.audioWorklet.addModule(
  './my-worklet.js',
);

source.connect(audioContext.destination);
```

```ts subtitle="Så må vi instantiere denne som en egen node"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);

await audioContext.audioWorklet.addModule(
  './my-worklet.js',
);
const workletNode = new AudioWorkletNode(
  audioContext,
  'myworklet',
);

source.connect(audioContext.destination);
```

```ts subtitle="Og deretter connecte denne på samme måte i pipeline"
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);

await audioContext.audioWorklet.addModule(
  './my-worklet.js',
);
const workletNode = new AudioWorkletNode(
  audioContext,
  'myworklet',
);

source
  .connect(workletNode)
  .connect(audioContext.destination);
```

```ts
const stream = await navigator.mediaDevices.getUserMedia({
  audio: true,
});
const audioContext = new AudioContext();
const source = audioContext.createMediaStreamSource(stream);

await audioContext.audioWorklet.addModule(
  './my-worklet.js',
);
const workletNode = new AudioWorkletNode(
  audioContext,
  'myworklet',
);

source
  .connect(workletNode)
  .connect(audioContext.destination);
```

</CodeSurfer>

